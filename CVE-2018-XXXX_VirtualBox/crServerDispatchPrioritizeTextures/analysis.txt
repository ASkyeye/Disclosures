Buffer overflow in crServerDispatchPrioritizeTextures

Testing: VirtualBox v5.2.12 x64 
VM: Windows 7 x64
Host OS: Windows 10 x64, April 2018


Integer overflow in crServerDispatchPrioritizeTextures (VirtualBox-5.2.12/src/VBox/HostServices/SharedOpenGL/crserverlib/server_texture.c):

void SERVER_DISPATCH_APIENTRY crServerDispatchPrioritizeTextures( GLsizei n, const GLuint * textures, const GLclampf * priorities )
{
    GLuint *newTextures = (GLuint *) crAlloc(n * sizeof(GLuint)); // <——————— (1)
    GLint i;

    if (!newTextures)
    {
        crError("crServerDispatchDeleteTextures: out of memory");
        return;
    }

    crStatePrioritizeTextures(n, textures, priorities);

    for (i = 0; i < n; i++)
    {
        newTextures[i] = crStateGetTextureHWID(textures[i]); <——————— (0)
    }

    cr_server.head_spu->dispatch_table.PrioritizeTextures(n, newTextures, priorities);
    crFree(newTextures);
}

On line 1, the number of bytes to be allocated is calculated from the input argument `n`, which is fully controlled by the Guest VM via Chromium protocol. The `n` variable is of type GLsizei, which is a signed integer, and GLuint is of size 4. Therefore the expression will evaluate to 0 if the value of `n` is 0x40000000. crAlloc then will allocate a zero-sized buffer. Follows is an out of bounds write (line 0) of possibly 0x40000000 bytes of length. 

See also: 
windbg.log - demonstration of a heap corruption
VirtualBox.log - crash log from VirtualBox VM